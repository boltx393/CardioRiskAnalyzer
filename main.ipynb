{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving visualizations\n",
    "os.makedirs('visualizations', exist_ok=True)\n",
    "\n",
    "# Function to save figures\n",
    "def save_figure(fig, filename):\n",
    "    fig.savefig(os.path.join('visualizations', filename))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the data\n",
    "df = pd.read_csv(r'C:\\Users\\iamaa\\OneDrive\\Documents\\GitHub\\heartDiseaseRiskAssessment\\heart_2022_with_nans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (445132, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 445132 entries, 0 to 445131\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   State                      445132 non-null  object \n",
      " 1   Sex                        445132 non-null  object \n",
      " 2   GeneralHealth              443934 non-null  object \n",
      " 3   PhysicalHealthDays         434205 non-null  float64\n",
      " 4   MentalHealthDays           436065 non-null  float64\n",
      " 5   LastCheckupTime            436824 non-null  object \n",
      " 6   PhysicalActivities         444039 non-null  object \n",
      " 7   SleepHours                 439679 non-null  float64\n",
      " 8   RemovedTeeth               433772 non-null  object \n",
      " 9   HadHeartAttack             442067 non-null  object \n",
      " 10  HadAngina                  440727 non-null  object \n",
      " 11  HadStroke                  443575 non-null  object \n",
      " 12  HadAsthma                  443359 non-null  object \n",
      " 13  HadSkinCancer              441989 non-null  object \n",
      " 14  HadCOPD                    442913 non-null  object \n",
      " 15  HadDepressiveDisorder      442320 non-null  object \n",
      " 16  HadKidneyDisease           443206 non-null  object \n",
      " 17  HadArthritis               442499 non-null  object \n",
      " 18  HadDiabetes                444045 non-null  object \n",
      " 19  DeafOrHardOfHearing        424485 non-null  object \n",
      " 20  BlindOrVisionDifficulty    423568 non-null  object \n",
      " 21  DifficultyConcentrating    420892 non-null  object \n",
      " 22  DifficultyWalking          421120 non-null  object \n",
      " 23  DifficultyDressingBathing  421217 non-null  object \n",
      " 24  DifficultyErrands          419476 non-null  object \n",
      " 25  SmokerStatus               409670 non-null  object \n",
      " 26  ECigaretteUsage            409472 non-null  object \n",
      " 27  ChestScan                  389086 non-null  object \n",
      " 28  RaceEthnicityCategory      431075 non-null  object \n",
      " 29  AgeCategory                436053 non-null  object \n",
      " 30  HeightInMeters             416480 non-null  float64\n",
      " 31  WeightInKilograms          403054 non-null  float64\n",
      " 32  BMI                        396326 non-null  float64\n",
      " 33  AlcoholDrinkers            398558 non-null  object \n",
      " 34  HIVTesting                 379005 non-null  object \n",
      " 35  FluVaxLast12               398011 non-null  object \n",
      " 36  PneumoVaxEver              368092 non-null  object \n",
      " 37  TetanusLast10Tdap          362616 non-null  object \n",
      " 38  HighRiskLastYear           394509 non-null  object \n",
      " 39  CovidPos                   394368 non-null  object \n",
      "dtypes: float64(6), object(34)\n",
      "memory usage: 135.8+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Description:\n",
      "       PhysicalHealthDays  MentalHealthDays     SleepHours  HeightInMeters  \\\n",
      "count       434205.000000     436065.000000  439679.000000   416480.000000   \n",
      "mean             4.347919          4.382649       7.022983        1.702691   \n",
      "std              8.688912          8.387475       1.502425        0.107177   \n",
      "min              0.000000          0.000000       1.000000        0.910000   \n",
      "25%              0.000000          0.000000       6.000000        1.630000   \n",
      "50%              0.000000          0.000000       7.000000        1.700000   \n",
      "75%              3.000000          5.000000       8.000000        1.780000   \n",
      "max             30.000000         30.000000      24.000000        2.410000   \n",
      "\n",
      "       WeightInKilograms            BMI  \n",
      "count      403054.000000  396326.000000  \n",
      "mean           83.074470      28.529842  \n",
      "std            21.448173       6.554889  \n",
      "min            22.680000      12.020000  \n",
      "25%            68.040000      24.130000  \n",
      "50%            80.740000      27.440000  \n",
      "75%            95.250000      31.750000  \n",
      "max           292.570000      99.640000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Description:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "State                            0\n",
      "Sex                              0\n",
      "GeneralHealth                 1198\n",
      "PhysicalHealthDays           10927\n",
      "MentalHealthDays              9067\n",
      "LastCheckupTime               8308\n",
      "PhysicalActivities            1093\n",
      "SleepHours                    5453\n",
      "RemovedTeeth                 11360\n",
      "HadHeartAttack                3065\n",
      "HadAngina                     4405\n",
      "HadStroke                     1557\n",
      "HadAsthma                     1773\n",
      "HadSkinCancer                 3143\n",
      "HadCOPD                       2219\n",
      "HadDepressiveDisorder         2812\n",
      "HadKidneyDisease              1926\n",
      "HadArthritis                  2633\n",
      "HadDiabetes                   1087\n",
      "DeafOrHardOfHearing          20647\n",
      "BlindOrVisionDifficulty      21564\n",
      "DifficultyConcentrating      24240\n",
      "DifficultyWalking            24012\n",
      "DifficultyDressingBathing    23915\n",
      "DifficultyErrands            25656\n",
      "SmokerStatus                 35462\n",
      "ECigaretteUsage              35660\n",
      "ChestScan                    56046\n",
      "RaceEthnicityCategory        14057\n",
      "AgeCategory                   9079\n",
      "HeightInMeters               28652\n",
      "WeightInKilograms            42078\n",
      "BMI                          48806\n",
      "AlcoholDrinkers              46574\n",
      "HIVTesting                   66127\n",
      "FluVaxLast12                 47121\n",
      "PneumoVaxEver                77040\n",
      "TetanusLast10Tdap            82516\n",
      "HighRiskLastYear             50623\n",
      "CovidPos                     50764\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names and Data Types:\n",
      "State                         object\n",
      "Sex                           object\n",
      "GeneralHealth                 object\n",
      "PhysicalHealthDays           float64\n",
      "MentalHealthDays             float64\n",
      "LastCheckupTime               object\n",
      "PhysicalActivities            object\n",
      "SleepHours                   float64\n",
      "RemovedTeeth                  object\n",
      "HadHeartAttack                object\n",
      "HadAngina                     object\n",
      "HadStroke                     object\n",
      "HadAsthma                     object\n",
      "HadSkinCancer                 object\n",
      "HadCOPD                       object\n",
      "HadDepressiveDisorder         object\n",
      "HadKidneyDisease              object\n",
      "HadArthritis                  object\n",
      "HadDiabetes                   object\n",
      "DeafOrHardOfHearing           object\n",
      "BlindOrVisionDifficulty       object\n",
      "DifficultyConcentrating       object\n",
      "DifficultyWalking             object\n",
      "DifficultyDressingBathing     object\n",
      "DifficultyErrands             object\n",
      "SmokerStatus                  object\n",
      "ECigaretteUsage               object\n",
      "ChestScan                     object\n",
      "RaceEthnicityCategory         object\n",
      "AgeCategory                   object\n",
      "HeightInMeters               float64\n",
      "WeightInKilograms            float64\n",
      "BMI                          float64\n",
      "AlcoholDrinkers               object\n",
      "HIVTesting                    object\n",
      "FluVaxLast12                  object\n",
      "PneumoVaxEver                 object\n",
      "TetanusLast10Tdap             object\n",
      "HighRiskLastYear              object\n",
      "CovidPos                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print column names and data types\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Variable 'HadHeartAttack' Data Type: object\n",
      "\n",
      "Unique values in 'HadHeartAttack': ['No' 'Yes' nan]\n"
     ]
    }
   ],
   "source": [
    "# Identify the target variable\n",
    "target_variable = 'HadHeartAttack'\n",
    "print(f\"\\nTarget Variable '{target_variable}' Data Type:\", df[target_variable].dtype)\n",
    "print(f\"\\nUnique values in '{target_variable}':\", df[target_variable].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Visualize original data\n",
    "# Correlation heatmap for numeric features\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(df[numeric_features].corr(), annot=False, cmap='coolwarm', linewidths=0.5, ax=ax)\n",
    "ax.set_title('Correlation Heatmap of Numerical Features')\n",
    "save_figure(fig, 'correlation_heatmap_original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "df[target_variable].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_title(f'Distribution of {target_variable} Cases')\n",
    "ax.set_xlabel(target_variable)\n",
    "ax.set_ylabel('Count')\n",
    "save_figure(fig, 'target_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocess the data\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Ensure target variable is not in feature lists\n",
    "if target_variable in numeric_features:\n",
    "    numeric_features = numeric_features.drop(target_variable)\n",
    "if target_variable in categorical_features:\n",
    "    categorical_features = categorical_features.drop(target_variable)\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the data\n",
    "X = df.drop(target_variable, axis=1)\n",
    "y = df[target_variable]\n",
    "\n",
    "# Convert target variable to numeric if it's categorical\n",
    "if y.dtype == 'object':\n",
    "    y = pd.get_dummies(y, drop_first=True).iloc[:, 0]\n",
    "\n",
    "X_preprocessed = preprocessing_pipeline.fit_transform(X)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "cat_feature_names = onehot_encoder.get_feature_names_out(categorical_features)\n",
    "feature_names = list(numeric_features) + list(cat_feature_names)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df_preprocessed = pd.DataFrame(X_preprocessed.toarray(), columns=feature_names)\n",
    "df_preprocessed[target_variable] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize preprocessed data\n",
    "# Correlation heatmap of preprocessed data\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(df_preprocessed.corr(), annot=False, cmap='coolwarm', linewidths=0.5, ax=ax)\n",
    "ax.set_title('Correlation Heatmap of Preprocessed Features')\n",
    "save_figure(fig, 'correlation_heatmap_preprocessed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocessed.drop(target_variable, axis=1), df_preprocessed[target_variable], test_size=0.25, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.9461463116558684\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.99      0.97    104989\n",
      "        True       0.55      0.25      0.34      6294\n",
      "\n",
      "    accuracy                           0.95    111283\n",
      "   macro avg       0.75      0.62      0.66    111283\n",
      "weighted avg       0.93      0.95      0.94    111283\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103729   1260]\n",
      " [  4733   1561]]\n"
     ]
    }
   ],
   "source": [
    "# 6. Train and evaluate models\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.9464967694975872\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.99      0.97    104989\n",
      "        True       0.59      0.17      0.26      6294\n",
      "\n",
      "    accuracy                           0.95    111283\n",
      "   macro avg       0.77      0.58      0.62    111283\n",
      "weighted avg       0.93      0.95      0.93    111283\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104261    728]\n",
      " [  5226   1068]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature importance (for Random Forest)\n",
    "feature_importance = pd.DataFrame({'feature': X_train.columns, 'importance': rf_model.feature_importances_})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20), ax=ax)\n",
    "ax.set_title('Top 20 Feature Importance (Random Forest)')\n",
    "save_figure(fig, 'feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained Variance Ratios by PCA Components:\n",
      "[0.23229727 0.1133136  0.06505329 0.06240663 0.03913342 0.03052855\n",
      " 0.02282342 0.02160606 0.01834263 0.01602356]\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA after preprocessing\n",
    "n_components = 10  \n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit PCA on the preprocessed data (excluding target variable)\n",
    "X_pca = pca.fit_transform(df_preprocessed.drop(target_variable, axis=1))\n",
    "\n",
    "# Display explained variance ratios for each component\n",
    "print(\"\\nExplained Variance Ratios by PCA Components:\")\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA-Transformed Data (first few rows):\n",
      "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0 -1.482430 -0.337281  0.016872 -0.551503 -0.656689 -0.312154  0.198048   \n",
      "1 -1.541383 -0.212033 -0.864492 -0.749205 -0.373818 -1.195581 -1.010707   \n",
      "2 -0.854133  0.188091 -1.149555 -0.443943 -0.112956 -1.365193 -0.692408   \n",
      "3 -1.412349 -0.435456 -1.168436 -0.568296 -1.490527  0.858088 -0.381260   \n",
      "4 -1.218443 -0.553269 -1.798268 -0.755508 -0.587452 -0.020735  0.391304   \n",
      "\n",
      "        PC8       PC9      PC10  HadHeartAttack  \n",
      "0  0.897981 -0.578438 -0.023269           False  \n",
      "1  0.984390 -0.920374 -0.573150           False  \n",
      "2 -0.280108 -0.801381 -0.141610           False  \n",
      "3 -0.093023 -0.294754  0.123212           False  \n",
      "4  0.697714  0.386159 -0.346730           False  \n"
     ]
    }
   ],
   "source": [
    "# Convert PCA results to DataFrame\n",
    "df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])\n",
    "df_pca[target_variable] = df_preprocessed[target_variable]\n",
    "\n",
    "print(\"\\nPCA-Transformed Data (first few rows):\")\n",
    "print(df_pca.head())\n",
    "\n",
    "# Split the PCA-transformed data\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(df_pca.drop(target_variable, axis=1), df_pca[target_variable], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results (PCA):\n",
      "Accuracy: 0.9424331944241634\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      1.00      0.97     83889\n",
      "        True       0.53      0.02      0.05      5138\n",
      "\n",
      "    accuracy                           0.94     89027\n",
      "   macro avg       0.74      0.51      0.51     89027\n",
      "weighted avg       0.92      0.94      0.92     89027\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83775   114]\n",
      " [ 5011   127]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models using PCA-transformed data\n",
    "# Logistic Regression\n",
    "lr_model_pca = LogisticRegression(random_state=42)\n",
    "lr_model_pca.fit(X_train_pca, y_train)\n",
    "lr_pred_pca = lr_model_pca.predict(X_test_pca)\n",
    "lr_accuracy_pca = accuracy_score(y_test, lr_pred_pca)\n",
    "\n",
    "print(\"\\nLogistic Regression Results (PCA):\")\n",
    "print(\"Accuracy:\", lr_accuracy_pca)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_pred_pca))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lr_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results (PCA):\n",
      "Accuracy: 0.9421636132858571\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      1.00      0.97     83889\n",
      "        True       0.46      0.01      0.02      5138\n",
      "\n",
      "    accuracy                           0.94     89027\n",
      "   macro avg       0.70      0.51      0.50     89027\n",
      "weighted avg       0.91      0.94      0.92     89027\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[83817    72]\n",
      " [ 5077    61]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest using PCA-transformed data\n",
    "rf_model_pca = RandomForestClassifier(random_state=42)\n",
    "rf_model_pca.fit(X_train_pca, y_train)\n",
    "rf_pred_pca = rf_model_pca.predict(X_test_pca)\n",
    "rf_accuracy_pca = accuracy_score(y_test, rf_pred_pca)\n",
    "\n",
    "print(\"\\nRandom Forest Results (PCA):\")\n",
    "print(\"Accuracy:\", rf_accuracy_pca)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred_pca))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize explained variance ratios of PCA components\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x=[f'PC{i+1}' for i in range(len(pca.explained_variance_ratio_))], y=pca.explained_variance_ratio_, ax=ax)\n",
    "ax.set_title('Explained Variance Ratio by PCA Components')\n",
    "ax.set_ylabel('Explained Variance Ratio')\n",
    "save_figure(fig, 'pca_explained_variance.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
